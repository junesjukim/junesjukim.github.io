<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unmanned Orchard Robot | June Sungjoo Kim </title> <meta name="author" content="June Sungjoo Kim"> <meta name="description" content="Vision-Based Autonomous Guidance and Yield Monitoring"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://junesjukim.github.io/projects/unmanned_orchard_robot/"> <script src="/assets/js/theme.js?7f7c34135a72954c2d1252944009308c"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">June</span> Sungjoo Kim </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repos </a> </li> <li class="nav-item "> <a class="nav-link" href="/studies/index.html">studies </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unmanned Orchard Robot</h1> <p class="post-description">Vision-Based Autonomous Guidance and Yield Monitoring</p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/4-480.webp 480w,/assets/img/4-800.webp 800w,/assets/img/4-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/4.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Unmanned Orchard Robot in Action" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The unmanned robot navigating a test environment designed to mimic a real orchard. </div> <hr> <h3 id="1-overview"><strong>1. Overview</strong></h3> <p>This project introduces a <strong>ROS-based autonomous robot</strong> designed for modernizing orchard management. By leveraging computer vision and SLAM, the robot can navigate orchard rows, monitor fruit growth status, and detect diseases in real-time. This system aims to solve critical challenges in precision agriculture, such as labor shortages and the need for timely data-driven interventions. Our key achievement was the development of a fully integrated platform that successfully performed these tasks in a complex environment, ultimately winning the <strong>Grand Prize at the Agricultural Robot Competition</strong> hosted by the Rural Development Administration of Korea.</p> <hr> <h3 id="2-the-challenge-precision-agriculture-in-orchards"><strong>2. The Challenge: Precision Agriculture in Orchards</strong></h3> <p>Orchard environments pose unique challenges for automation.</p> <ul> <li> <strong>GNSS-Denied Environment:</strong> Dense canopies block GPS signals, making standard navigation methods unreliable.</li> <li> <strong>Unstructured Terrain:</strong> Irregular row spacing and scattered obstacles require robust perception and dynamic path planning.</li> <li> <strong>Variable Conditions:</strong> Fluctuating light and weather conditions demand a vision system that is resilient to change.</li> </ul> <p>Our goal was to build a cost-effective robot that could reliably operate under these constraints using primarily vision and LiDAR sensors.</p> <hr> <h3 id="3-system-architecture"><strong>3. System Architecture</strong></h3> <p>The robot is built on a modular hardware and software architecture to ensure flexibility and robustness.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/system_diagram-480.webp 480w,/assets/img/system_diagram-800.webp 800w,/assets/img/system_diagram-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/system_diagram.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Hardware Architecture" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/algorithm_overview-480.webp 480w,/assets/img/algorithm_overview-800.webp 800w,/assets/img/algorithm_overview-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/algorithm_overview.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Software Flow" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> **Left:** A diagram of the core hardware components and their connections. **Right:** The high-level software process flow from sensing to action. </div> <ul> <li> <strong>Hardware Stack</strong>: <ul> <li> <strong>Chassis</strong>: TurtleBot3 Burger</li> <li> <strong>Single Board Computer</strong>: NVIDIA Jetson Nano</li> <li> <strong>Primary Sensor (SLAM)</strong>: RPLiDAR A2M8 2D LiDAR</li> <li> <strong>Vision Sensors</strong>: 2 x Logitech C270 Webcams</li> <li> <strong>Controller</strong>: OpenCR 1.0 with Dynamixel motors</li> </ul> </li> <li> <strong>Software Stack</strong>: <ul> <li> <strong>OS</strong>: Ubuntu 18.04</li> <li> <strong>Framework</strong>: Robot Operating System (ROS1) Melodic</li> <li> <strong>Key Libraries</strong>: <code class="language-plaintext highlighter-rouge">GMapping</code> for SLAM, <code class="language-plaintext highlighter-rouge">Pytorch</code> for deep learning, <code class="language-plaintext highlighter-rouge">OpenCV</code> for image processing.</li> </ul> </li> </ul> <hr> <h3 id="4-core-technologies"><strong>4. Core Technologies</strong></h3> <h4 id="autonomous-navigation-with-slam"><strong>Autonomous Navigation with SLAM</strong></h4> <p>To navigate without GPS, the robot uses the <strong>GMapping SLAM</strong> algorithm. The 2D LiDAR sensor scans the environment to build a map of tree trunks and other obstacles. This map, combined with wheel odometry data from the Dynamixel motors, allows the robot to accurately determine its position and navigate autonomously along the orchard rows.</p> <p><em><code class="language-plaintext highlighter-rouge">[Here, you can add more technical details about the SLAM implementation, such as parameter tuning or how you handled sensor fusion. A GIF showing the map being built in RViz would be perfect here.]</code></em></p> <h4 id="fruit-and-disease-detection-with-yolov5"><strong>Fruit and Disease Detection with YOLOv5</strong></h4> <p>We developed a real-time object detection model to identify and classify fruits.</p> <ol> <li> <strong>Data Collection</strong>: We captured over 1,000 images from the testbed environment under various lighting conditions.</li> <li> <strong>Model Training</strong>: We fine-tuned a <strong>YOLOv5n</strong> model on a custom dataset with three classes: <code class="language-plaintext highlighter-rouge">Tree</code>, <code class="language-plaintext highlighter-rouge">Fruit</code>, and <code class="language-plaintext highlighter-rouge">SickFruit</code>. The model was optimized for performance on the edge (NVIDIA Jetson Nano).</li> <li> <strong>Performance</strong>: The final model achieved <strong>97% accuracy</strong> on the test set, demonstrating its ability to reliably detect targets for yield monitoring.</li> </ol> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/yolo_detection_example-480.webp 480w,/assets/img/yolo_detection_example-800.webp 800w,/assets/img/yolo_detection_example-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/yolo_detection_example.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Real-time Fruit Detection" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A demonstration of the YOLOv5 model identifying healthy and sick fruits in real-time. </div> <hr> <h3 id="5-results--demonstration"><strong>5. Results &amp; Demonstration</strong></h3> <p>The final integrated system was tested in a mock orchard environment. The robot successfully navigated the rows, detected all target trees, and created a position map of healthy and diseased fruits. The project’s success was recognized with the <strong>Grand Prize</strong> at the 60th-anniversary Agricultural Robot Competition.</p> <p><em><code class="language-plaintext highlighter-rouge">[This is a great place to add a full video of the robot completing its mission. You can also add more images or a small gallery showing different aspects of the project.]</code></em></p> <hr> <h3 id="6-conclusion--future-work"><strong>6. Conclusion &amp; Future Work</strong></h3> <p>This project successfully demonstrated the feasibility of a low-cost, vision-based robot for orchard automation. The modular design allows for future enhancements.</p> <p>Potential next steps include:</p> <ul> <li>Testing and fine-tuning the system in a real-world orchard.</li> <li>Integrating a robotic arm for automated harvesting or spot-spraying based on detection results.</li> <li>Improving long-term localization robustness with advanced visual SLAM techniques.</li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 June Sungjoo Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>